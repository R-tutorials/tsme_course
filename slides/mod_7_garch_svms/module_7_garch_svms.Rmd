---
title: 'Module 7: Heteroskedasticity; ARCH, GARCH and SVMs'
author: "Andrew Parnell, School of Mathematics and Statistics, University College Dublin"
output:
  ioslides_presentation:
    logo: http://www.ucd.ie/handball/images/ucd_brandmark_colour.gif
    transition: slower
    widescreen: yes
  beamer_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align='center')
library(latex2exp)
library(R2jags)
```

## Learning outcomes

- Understand how to fit ARCH, GARCH and SVM models in JAGS
- Know how to check assumptions for these methods
- Know how to perform cross-validation as an alternative to model selection
- Know the basics of forecast calibration and scoring rules

Relevant JAGS file:
```
jags_ARCH.R
jags_GARCH.R
jags_SVM.R
```

## General principles of models for changing variance

- So far we have looked at models where the mean changes but the variance is constant:
$$y_t \sim N(\mu_t, \sigma^2)$$
- In this module we look at methods where instead:
$$y_t \sim N(\alpha, \sigma_t^2)$$
- These are:
  - Autoregressive Conditional Heteroskedasticity (ARCH) 
  - Generalised Autoregressive Conditional Heteroskedasticity (ARCH) 
  - Stochastic Volatility Models (SVM)

## Extension 1: ARCH 

- An ARCH(1) Model has the form:
$$\sigma_t^2 = \gamma_0 + \gamma_1 \epsilon_{t-1}^2$$
where $\epsilon_{t}$ is the residual, just like an MA model
- Note that $\epsilon_t = y_t - \alpha$ so the above can be re-written as:
$$\sigma_t^2 = \gamma_0 + \gamma_1 (y_{t-1} - \alpha)^2$$
- The variance at time $t$ thus depends on the previous value of the series (hence the autoregressive in the name)
- The residual needs to be squared to keep the variance positive. 
- The parameters $\gamma_0$ and $\gamma_1$ also need to be positive, and usually $\gamma_1 \sim U(0,1)$

## JAGS code for ARCH models
```{r}
model_code = '
model
{
  # Likelihood
  for (t in 1:T) {
    y[t] ~ dnorm(alpha, tau[t])
    tau[t] <- 1/pow(sigma[t], 2)
  }
  sigma[1] ~ dunif(0, 10)
  for(t in 2:T) {
    sigma[t] <- sqrt( gamma_1 + gamma_2 * pow(y[t-1] - alpha, 2) )
  }

  # Priors
  alpha ~ dnorm(0.0, 0.01)
  gamma_1 ~ dunif(0, 10)
  gamma_2 ~ dunif(0, 1)
}
'
```

## Example: ice core data

```{r, include=FALSE}
ice = read.csv('https://raw.githubusercontent.com/andrewcparnell/tsme_course/master/data/GISP2_20yr.csv')
ice2 = subset(ice,Age>=10000 & Age<=25000)
# Set up the data
real_data = with(ice2,
                 list(T = nrow(ice2) - 1, y = diff(Del.18O)))

# Save the sigma's the most interesting part!
model_parameters = c('sigma','alpha','gamma_1','gamma_2')

# Run the model - requires longer to converge
real_data_run_1 = jags(data = real_data,
                     parameters.to.save = model_parameters,
                     model.file=textConnection(model_code),
                     n.chains=4,
                     n.iter=1000,
                     n.burnin=200,
                     n.thin=2)
```
```{r}
with(ice2,plot(Age[-1],diff(Del.18O),type='l'))
```

## Example: ice core output
```{r}
par(mfrow=c(1,2))
hist(real_data_run_1$BUGSoutput$sims.list$gamma_1, breaks=30)
hist(real_data_run_1$BUGSoutput$sims.list$gamma_2, breaks=30)
```

## Example: posterior standard deviations

```{r}
sigma_med = apply(real_data_run_1$BUGSoutput$sims.list$sigma,2,'quantile',0.5)
plot(ice2$Age[-1],sigma_med,type='l',ylim=range(c(sigma_med[-1])))
```

## From ARCH to GARCH

- The Generalised ARCH model works by simply adding the previous value of the variance, as well as the previous value of the observation
- The GARCH(1,1) model thus has:
$$\sigma_t^2 = \gamma_1 + \gamma_2 * (y_{t-1} - \alpha)^2 + \gamma_3 * \sigma_{t-1}^2$$
- Strictly speaking $\gamma_1 + \gamma_2 < 1$ though like the stationarity conditions in ARIMA models we can relax this assumption and see if the data support it
- It's conceptually easy to extend to general GARCH(p,q) models which add in extra previous lags

## Example of using the GARCH(1,1) model

```{r}
model_code = '
model
{
  # Likelihood
  for (t in 1:T) {
    y[t] ~ dnorm(alpha, tau[t])
    tau[t] <- 1/pow(sigma[t], 2)
  }
  sigma[1] ~ dunif(0,10)
  for(t in 2:T) {
    sigma[t] <- sqrt( gamma_1 + gamma_2 * pow(y[t-1] - alpha, 2) + gamma_3 * pow(sigma[t-1], 2) )
  }

  # Priors
  alpha ~ dnorm(0.0, 0.01)
  gamma_1 ~ dunif(0, 10)
  gamma_2 ~ dunif(0, 1)
  gamma_3 ~ dunif(0, 1)
}
'
```

## Using the ice core data again
```{r, include=FALSE}
model_parameters = c('sigma', 'alpha', 'gamma_1', 'gamma_2', 'gamma_3')

# Run the model - requires longer to converge
real_data_run_2 = jags(data = real_data,
                     parameters.to.save = model_parameters,
                     model.file=textConnection(model_code),
                     n.chains=4,
                     n.iter=1000,
                     n.burnin=200,
                     n.thin=2)
```

Have a look at the ARCH parameters;

```{r}
par(mfrow=c(1,3))
hist(real_data_run_2$BUGSoutput$sims.list$gamma_1, breaks=30, xlab = 'gamma 1')
hist(real_data_run_2$BUGSoutput$sims.list$gamma_2, breaks=30, xlab = 'gamma 2')
hist(real_data_run_2$BUGSoutput$sims.list$gamma_3, breaks=30, xlab = 'gamma 3')
```

## Posterior median standard deviation

```{r}
sigma_med = apply(real_data_run_2$BUGSoutput$sims.list$sigma, 2, 'quantile', 0.5)
plot(ice2$Age[-1], sigma_med, type='l', ylim=range(c(sigma_med)))
```

## Compare with DIC

```{r, echo=FALSE, message=FALSE}
r_1 = print(real_data_run_1)
r_2 = print(real_data_run_2)
```
```{r}
with(r_1, print(c(DIC, pD)))
with(r_2, print(c(DIC, pD)))
```

- Suggests full GARCH model is best, despite the extra parameters

## Stochastic Volatility Modelling

- Both ARCH and GARCH propose a deterministic relationship for the current variance parameter
- By contrast a Stochastic Volatility Model (SVM) models the variance as its own _stochastic process_
- SVMs, ARCH and GARCH are all closely linked if you into the bowels of the theory
- The general model structure is often written as:
$$y_t \sim N( \alpha, \exp( h_t ) )$$
$$h_t \sim N( \mu + \phi ( h_{t-1} - \mu), \sigma^2)$$
- You can think of an SVM being like a GLM but with a log link on the variance parameter

## JAGS code for the SVM model
```{r}
model_code = '
model
{
  # Likelihood
  for (t in 1:T) {
    y[t] ~ dnorm(alpha, tau_h[t])
    tau_h[t] <- 1/exp(h[t])
  }
  h[1] <- mu
  for(t in 2:T) {
    h[t] ~ dnorm(mu + phi * (h[t-1] - mu), tau)
  }

  # Priors
  alpha ~ dnorm(0, 0.01)
  mu ~ dnorm(0, 0.01)
  phi ~ dunif(-1, 1)
  tau <- 1/pow(sigma, 2)
  sigma ~ dunif(0,100)
}
'
```

## Example of SVMs and comparison of DIC


## Measuring the quality of a forecast; scoring rules


## Summary